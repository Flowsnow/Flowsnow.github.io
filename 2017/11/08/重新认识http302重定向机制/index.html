<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>重新认识HTTP3xx重定向机制 - Suncle&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Suncle" /><meta name="description" content="问题引入 前段时间做数据收集时需要下载网宿cdn的日志进行分析。而网宿对日志下载的接口搞得很复杂，又没有提供相应的sdk，只是提供了一个shell脚本，虽然在ubuntu上使用很方便，但是脚本里面的各种重定向分析非常复杂。故此想对重定向在深入了解一点。
查询网宿日志列表的脚本
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  #!/bin/sh  TMP_FILE=&amp;#34;/tmp/wslog_query_client.log&amp;#34; #Usage Usage() { echo &amp;#34;wslog_query_client.sh [query_url] [user] [passwd] [start_time] [end_time] [channels]&amp;#34; return 0 } #check input parameters if [ $# -eq 1 ]; then if [ &amp;#34;$1&amp;#34; = &amp;#34;-h&amp;#34; ]; then Usage exit 0 else Usage exit -1 fi elif [ $# -ne 6 ]; then Usage exit -1 fi #params set url=$1 user=$2 passwd=`echo $3 | sed &amp;#39;s/&amp;amp;/%26/g&amp;#39; ` start_time=$4 end_time=$5 channels=$6 #access logQuery access API curl -s -D $TMP_FILE $1 cat $TMP_FILE | grep &amp;#34;HTTP/&amp;#34; | grep &amp;#34;302&amp;#34; &amp;gt; /dev/null if [ $? -ne 0 ]; then exit -2 fi #redirect to verify url with user and passwd TMP_URL=`cat $TMP_FILE | grep &amp;#34;Location: &amp;#34;|sed &amp;#39;s/\r//&amp;#39; | awk &amp;#39;{print $2}&amp;#39; | sed &amp;#39;s/http:/https:/&amp;#39;` TMP_URL=&amp;#34;${TMP_URL}?u=$user&amp;amp;p=$passwd&amp;amp;channel=$channels&amp;#34; curl -s -k -D $TMP_FILE $TMP_URL cat $TMP_FILE | grep &amp;#34;HTTP/&amp;#34; | grep &amp;#34;302&amp;#34; &amp;gt; /dev/null if [ $? -ne 0 ]; then exit -3 fi #redirect to query url with start_time, end_time and channels TMP_URL=`cat $TMP_FILE | grep &amp;#34;Location: &amp;#34;|sed &amp;#39;s/\r//&amp;#39; | awk &amp;#39;{print $2}&amp;#39;` TMP_URL=&amp;#34;${TMP_URL}&amp;amp;start_time=$start_time&amp;amp;end_time=$end_time&amp;amp;channels=$channels&amp;#34; curl -s -D $TMP_FILE $TMP_URL #check query result cat $TMP_FILE | grep &amp;#34;HTTP/&amp;#34; | grep &amp;#34;200&amp;#34; &amp;gt; /dev/null if [ $? -ne 0 ]; then if cat $TMP_FILE | grep &amp;#34;HTTP/&amp;#34; | grep &amp;#34;404&amp;#34; &amp;gt; /dev/null then exit -404 else exit -4 fi fi exit 0   " /><meta name="keywords" content="计算机, 后端, Python, golang" />






<meta name="generator" content="Hugo 0.74.3 with theme even" />


<link rel="canonical" href="https://suncle.me/2017/11/08/%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86http302%E9%87%8D%E5%AE%9A%E5%90%91%E6%9C%BA%E5%88%B6/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<link href="/sass/main.min.651e6917abb0239242daa570c2bec9867267bbcd83646da5a850afe573347b44.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="重新认识HTTP3xx重定向机制" />
<meta property="og:description" content="问题引入
前段时间做数据收集时需要下载网宿cdn的日志进行分析。而网宿对日志下载的接口搞得很复杂，又没有提供相应的sdk，只是提供了一个shell脚本，虽然在ubuntu上使用很方便，但是脚本里面的各种重定向分析非常复杂。故此想对重定向在深入了解一点。
查询网宿日志列表的脚本


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59


#!/bin/sh

TMP_FILE=&#34;/tmp/wslog_query_client.log&#34;
#Usage
Usage() {
	echo &#34;wslog_query_client.sh [query_url] [user] [passwd] [start_time] [end_time] [channels]&#34;
	return 0
}
#check input parameters
if [ $# -eq 1 ]; then
	if [ &#34;$1&#34; = &#34;-h&#34; ]; then
		Usage
		exit 0
	else
		Usage
		exit -1
	fi
elif [ $# -ne 6 ]; then
	Usage
	exit -1
fi
#params set
url=$1
user=$2
passwd=`echo $3 | sed &#39;s/&amp;/%26/g&#39; `
start_time=$4
end_time=$5
channels=$6
#access logQuery access API
curl -s -D $TMP_FILE $1
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -2
fi
#redirect to verify url with user and passwd
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39; | sed &#39;s/http:/https:/&#39;`
TMP_URL=&#34;${TMP_URL}?u=$user&amp;p=$passwd&amp;channel=$channels&#34;
curl -s -k -D $TMP_FILE $TMP_URL
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -3
fi
#redirect to query url with start_time, end_time and channels
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39;`
TMP_URL=&#34;${TMP_URL}&amp;start_time=$start_time&amp;end_time=$end_time&amp;channels=$channels&#34;
curl -s -D $TMP_FILE $TMP_URL
#check query result
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;200&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	if 
		cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;404&#34; &gt; /dev/null
	then
		exit -404
	else
		exit -4
	fi
fi
exit 0



" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://suncle.me/2017/11/08/%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86http302%E9%87%8D%E5%AE%9A%E5%90%91%E6%9C%BA%E5%88%B6/" />
<meta property="article:published_time" content="2017-11-08T20:24:43+00:00" />
<meta property="article:modified_time" content="2017-11-08T20:24:43+00:00" />
<meta itemprop="name" content="重新认识HTTP3xx重定向机制">
<meta itemprop="description" content="问题引入
前段时间做数据收集时需要下载网宿cdn的日志进行分析。而网宿对日志下载的接口搞得很复杂，又没有提供相应的sdk，只是提供了一个shell脚本，虽然在ubuntu上使用很方便，但是脚本里面的各种重定向分析非常复杂。故此想对重定向在深入了解一点。
查询网宿日志列表的脚本


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59


#!/bin/sh

TMP_FILE=&#34;/tmp/wslog_query_client.log&#34;
#Usage
Usage() {
	echo &#34;wslog_query_client.sh [query_url] [user] [passwd] [start_time] [end_time] [channels]&#34;
	return 0
}
#check input parameters
if [ $# -eq 1 ]; then
	if [ &#34;$1&#34; = &#34;-h&#34; ]; then
		Usage
		exit 0
	else
		Usage
		exit -1
	fi
elif [ $# -ne 6 ]; then
	Usage
	exit -1
fi
#params set
url=$1
user=$2
passwd=`echo $3 | sed &#39;s/&amp;/%26/g&#39; `
start_time=$4
end_time=$5
channels=$6
#access logQuery access API
curl -s -D $TMP_FILE $1
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -2
fi
#redirect to verify url with user and passwd
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39; | sed &#39;s/http:/https:/&#39;`
TMP_URL=&#34;${TMP_URL}?u=$user&amp;p=$passwd&amp;channel=$channels&#34;
curl -s -k -D $TMP_FILE $TMP_URL
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -3
fi
#redirect to query url with start_time, end_time and channels
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39;`
TMP_URL=&#34;${TMP_URL}&amp;start_time=$start_time&amp;end_time=$end_time&amp;channels=$channels&#34;
curl -s -D $TMP_FILE $TMP_URL
#check query result
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;200&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	if 
		cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;404&#34; &gt; /dev/null
	then
		exit -404
	else
		exit -4
	fi
fi
exit 0



">
<meta itemprop="datePublished" content="2017-11-08T20:24:43+00:00" />
<meta itemprop="dateModified" content="2017-11-08T20:24:43+00:00" />
<meta itemprop="wordCount" content="1378">



<meta itemprop="keywords" content="Http,重定向," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="重新认识HTTP3xx重定向机制"/>
<meta name="twitter:description" content="问题引入
前段时间做数据收集时需要下载网宿cdn的日志进行分析。而网宿对日志下载的接口搞得很复杂，又没有提供相应的sdk，只是提供了一个shell脚本，虽然在ubuntu上使用很方便，但是脚本里面的各种重定向分析非常复杂。故此想对重定向在深入了解一点。
查询网宿日志列表的脚本


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59


#!/bin/sh

TMP_FILE=&#34;/tmp/wslog_query_client.log&#34;
#Usage
Usage() {
	echo &#34;wslog_query_client.sh [query_url] [user] [passwd] [start_time] [end_time] [channels]&#34;
	return 0
}
#check input parameters
if [ $# -eq 1 ]; then
	if [ &#34;$1&#34; = &#34;-h&#34; ]; then
		Usage
		exit 0
	else
		Usage
		exit -1
	fi
elif [ $# -ne 6 ]; then
	Usage
	exit -1
fi
#params set
url=$1
user=$2
passwd=`echo $3 | sed &#39;s/&amp;/%26/g&#39; `
start_time=$4
end_time=$5
channels=$6
#access logQuery access API
curl -s -D $TMP_FILE $1
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -2
fi
#redirect to verify url with user and passwd
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39; | sed &#39;s/http:/https:/&#39;`
TMP_URL=&#34;${TMP_URL}?u=$user&amp;p=$passwd&amp;channel=$channels&#34;
curl -s -k -D $TMP_FILE $TMP_URL
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;302&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	exit -3
fi
#redirect to query url with start_time, end_time and channels
TMP_URL=`cat $TMP_FILE | grep &#34;Location: &#34;|sed &#39;s/\r//&#39; | awk &#39;{print $2}&#39;`
TMP_URL=&#34;${TMP_URL}&amp;start_time=$start_time&amp;end_time=$end_time&amp;channels=$channels&#34;
curl -s -D $TMP_FILE $TMP_URL
#check query result
cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;200&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
	if 
		cat $TMP_FILE | grep &#34;HTTP/&#34; | grep &#34;404&#34; &gt; /dev/null
	then
		exit -404
	else
		exit -4
	fi
fi
exit 0



"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Suncle&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Suncle&#39;s Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">重新认识HTTP3xx重定向机制</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-11-08 </span>
        <div class="post-category">
            <a href="/categories/Http/"> Http </a>
            </div>
          <span class="more-meta"> 约 1378 字 </span>
          <span class="more-meta"> 预计阅读 3 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#问题引入">问题引入</a></li>
    <li><a href="#http重定向的原理">HTTP重定向的原理</a></li>
    <li><a href="#http重定向的使用">HTTP重定向的使用</a>
      <ul>
        <li><a href="#python">Python</a></li>
        <li><a href="#shell">Shell</a></li>
      </ul>
    </li>
    <li><a href="#http重定向抓包验证">HTTP重定向抓包验证</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="问题引入">问题引入</h1>
<p>前段时间做数据收集时需要下载网宿cdn的日志进行分析。而网宿对日志下载的接口搞得很复杂，又没有提供相应的sdk，只是提供了一个shell脚本，虽然在ubuntu上使用很方便，但是脚本里面的各种重定向分析非常复杂。故此想对重定向在深入了解一点。</p>
<p><strong>查询网宿日志列表的脚本</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash"><span class="cp">#!/bin/sh
</span><span class="cp"></span>
<span class="nv">TMP_FILE</span><span class="o">=</span><span class="s2">&#34;/tmp/wslog_query_client.log&#34;</span>
<span class="c1">#Usage</span>
Usage<span class="o">()</span> <span class="o">{</span>
	<span class="nb">echo</span> <span class="s2">&#34;wslog_query_client.sh [query_url] [user] [passwd] [start_time] [end_time] [channels]&#34;</span>
	<span class="k">return</span> <span class="m">0</span>
<span class="o">}</span>
<span class="c1">#check input parameters</span>
<span class="k">if</span> <span class="o">[</span> <span class="nv">$#</span> -eq <span class="m">1</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="k">if</span> <span class="o">[</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span> <span class="o">=</span> <span class="s2">&#34;-h&#34;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
		Usage
		<span class="nb">exit</span> <span class="m">0</span>
	<span class="k">else</span>
		Usage
		<span class="nb">exit</span> -1
	<span class="k">fi</span>
<span class="k">elif</span> <span class="o">[</span> <span class="nv">$#</span> -ne <span class="m">6</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	Usage
	<span class="nb">exit</span> -1
<span class="k">fi</span>
<span class="c1">#params set</span>
<span class="nv">url</span><span class="o">=</span><span class="nv">$1</span>
<span class="nv">user</span><span class="o">=</span><span class="nv">$2</span>
<span class="nv">passwd</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="nv">$3</span> <span class="p">|</span> sed <span class="s1">&#39;s/&amp;/%26/g&#39;</span> <span class="sb">`</span>
<span class="nv">start_time</span><span class="o">=</span><span class="nv">$4</span>
<span class="nv">end_time</span><span class="o">=</span><span class="nv">$5</span>
<span class="nv">channels</span><span class="o">=</span><span class="nv">$6</span>
<span class="c1">#access logQuery access API</span>
curl -s -D <span class="nv">$TMP_FILE</span> <span class="nv">$1</span>
cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;HTTP/&#34;</span> <span class="p">|</span> grep <span class="s2">&#34;302&#34;</span> &gt; /dev/null
<span class="k">if</span> <span class="o">[</span> <span class="nv">$?</span> -ne <span class="m">0</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="nb">exit</span> -2
<span class="k">fi</span>
<span class="c1">#redirect to verify url with user and passwd</span>
<span class="nv">TMP_URL</span><span class="o">=</span><span class="sb">`</span>cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;Location: &#34;</span><span class="p">|</span>sed <span class="s1">&#39;s/\r//&#39;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $2}&#39;</span> <span class="p">|</span> sed <span class="s1">&#39;s/http:/https:/&#39;</span><span class="sb">`</span>
<span class="nv">TMP_URL</span><span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">TMP_URL</span><span class="si">}</span><span class="s2">?u=</span><span class="nv">$user</span><span class="s2">&amp;p=</span><span class="nv">$passwd</span><span class="s2">&amp;channel=</span><span class="nv">$channels</span><span class="s2">&#34;</span>
curl -s -k -D <span class="nv">$TMP_FILE</span> <span class="nv">$TMP_URL</span>
cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;HTTP/&#34;</span> <span class="p">|</span> grep <span class="s2">&#34;302&#34;</span> &gt; /dev/null
<span class="k">if</span> <span class="o">[</span> <span class="nv">$?</span> -ne <span class="m">0</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="nb">exit</span> -3
<span class="k">fi</span>
<span class="c1">#redirect to query url with start_time, end_time and channels</span>
<span class="nv">TMP_URL</span><span class="o">=</span><span class="sb">`</span>cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;Location: &#34;</span><span class="p">|</span>sed <span class="s1">&#39;s/\r//&#39;</span> <span class="p">|</span> awk <span class="s1">&#39;{print $2}&#39;</span><span class="sb">`</span>
<span class="nv">TMP_URL</span><span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">TMP_URL</span><span class="si">}</span><span class="s2">&amp;start_time=</span><span class="nv">$start_time</span><span class="s2">&amp;end_time=</span><span class="nv">$end_time</span><span class="s2">&amp;channels=</span><span class="nv">$channels</span><span class="s2">&#34;</span>
curl -s -D <span class="nv">$TMP_FILE</span> <span class="nv">$TMP_URL</span>
<span class="c1">#check query result</span>
cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;HTTP/&#34;</span> <span class="p">|</span> grep <span class="s2">&#34;200&#34;</span> &gt; /dev/null
<span class="k">if</span> <span class="o">[</span> <span class="nv">$?</span> -ne <span class="m">0</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="k">if</span> 
		cat <span class="nv">$TMP_FILE</span> <span class="p">|</span> grep <span class="s2">&#34;HTTP/&#34;</span> <span class="p">|</span> grep <span class="s2">&#34;404&#34;</span> &gt; /dev/null
	<span class="k">then</span>
		<span class="nb">exit</span> -404
	<span class="k">else</span>
		<span class="nb">exit</span> -4
	<span class="k">fi</span>
<span class="k">fi</span>
<span class="nb">exit</span> <span class="m">0</span>

</code></pre></td></tr></table>
</div>
</div><p>脚本调用命令和结果（用户名，密码，domain，wskey均已处理，调用结果只有参考作用）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">root@sz3:/tmp# sh /root/wslog_query_client.sh <span class="s2">&#34;http://dx.wslog.chinanetcenter.com/logQuery/access&#34;</span> user1 passwd1 2017-08-30-0000 2017-08-30-2359 <span class="s2">&#34;rtmp-wsz.enterprise.com&#34;</span>
<span class="o">{</span><span class="s2">&#34;logs&#34;</span>: <span class="o">[{</span><span class="s2">&#34;domain&#34;</span>: <span class="s2">&#34;rtmp-wsz.enterprise.com&#34;</span>, <span class="s2">&#34;files&#34;</span>: <span class="o">[{</span><span class="s2">&#34;size&#34;</span>: 4320, <span class="s2">&#34;end_time&#34;</span>: <span class="s2">&#34;2017-08-30-1159&#34;</span>, <span class="s2">&#34;start_time&#34;</span>: <span class="s2">&#34;2017-08-30-0000&#34;</span>, <span class="s2">&#34;url&#34;</span>: <span class="s2">&#34;http://dx.wslog.chinanetcenter.com/log/qukan/rtmp-wsz.enterprise.com/2017-08-30-0000-1130_rtmp-wsz.enterprise.com.cn.log.gz?wskey=e4030060bdfe9d5600a77726c5900d07aa3adae00e8b2&#34;</span><span class="o">}</span>, <span class="o">{</span><span class="s2">&#34;size&#34;</span>: 8006, <span class="s2">&#34;end_time&#34;</span>: <span class="s2">&#34;2017-08-30-2359&#34;</span>, <span class="s2">&#34;start_time&#34;</span>: <span class="s2">&#34;2017-08-30-1200&#34;</span>, <span class="s2">&#34;url&#34;</span>: <span class="s2">&#34;http://dx.wslog.chinanetcenter.com/log/qukan/rtmp-wsz.enterprise.com/2017-08-30-1200-2330_rtmp-wsz.enterprise.com.cn.log.gz?wskey=3772006094880e8300a73cc2c59006bfeea33ae00d9da&#34;</span><span class="o">}]}]}</span>
</code></pre></td></tr></table>
</div>
</div><p>脚本的调用过程是根据参数一步一步的进行302重定向，重定向时会依赖于参数，每次重定向依赖的参数都不相同，不仅仅是url跳转，如果直接使用以下http链接则无法跳转到，因此需要按照shell脚本那样一层一层解析。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">http://dx.wslog.chinanetcenter.com/logQuery/access?user=user1&amp;passwd=passwd1&amp;channels=rtmp-wsz.enterprise.com&amp;start_time=2017-08-30-0000&amp;end_time=2017-08-30-2359
</code></pre></td></tr></table>
</div>
</div><h1 id="http重定向的原理">HTTP重定向的原理</h1>
<p><img src="https://mdn.mozillademos.org/files/13785/HTTPRedirect.png" alt=""></p>
<p>客户端发起http请求，如果服务端返回http重定向响应，那么客户端会请求返回的新url，这就是重定向的过程，这个过程就是重定向。在客户端和服务端之间自动完成，用户不可见。</p>
<p>不同类型的重定向映射可以划分为三个类别：永久重定向、临时重定向和特殊重定向。</p>
<p>如果你想把自己的网站永久更改为一个新的域名，则应该使用301永久重定向，搜索引擎机器人会在遇到该状态码时触发更新操作，在其索引库中修改与该资源相关的 URL 。</p>
<h1 id="http重定向的使用">HTTP重定向的使用</h1>
<p>主要以Python和shell两种语言来介绍http重定向的使用。</p>
<h2 id="python">Python</h2>
<p>Python常用的http库urllib，urllib2，requests都支持http重定向。以requests库为例做介绍。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">requests</span>


<span class="k">def</span> <span class="nf">get_final_link</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">302</span> <span class="ow">or</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">301</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">get_final_link</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">headers</span><span class="p">[</span><span class="s1">&#39;Location&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">r</span><span class="o">.</span><span class="n">url</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">url</span>


<span class="k">def</span> <span class="nf">get_final_link1</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">rsp</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">history</span><span class="p">:</span>
        <span class="k">print</span> <span class="n">rsp</span><span class="o">.</span><span class="n">url</span>
    <span class="k">return</span> <span class="n">r</span><span class="o">.</span><span class="n">url</span>

<span class="k">print</span> <span class="n">get_final_link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://runreport.dnion.com/DCC/logDownLoad.do?user=user1&amp;password=password1&amp;domain=rtmpdist-d.quklive.com&amp;date=20171026&amp;hour=10&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">get_final_link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;https://github.com&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">get_final_link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://github.com&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">get_final_link1</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;http://github.com&#39;</span><span class="p">)</span>  <span class="c1"># 会发生301重定向</span>
</code></pre></td></tr></table>
</div>
</div><p>如果确定重定向的过程中全部都是http(s)请求，则allow_redirects参数设置成True即可得到最终的http链接。如果不是则需要自己进行递归解析。</p>
<p>如果是要简单的下载文件，则可以使用<code>urllib.urlretrieve</code>轻松胜任，即使最终链接是ftp。</p>
<h2 id="shell">Shell</h2>
<p>使用curl命令模拟</p>
<blockquote>
<p>-L参数，当页面有跳转的时候，输出跳转到的页面</p>
<p>-I参数  header信息  当有跳转时，可以通过 curl -L -I URL|grep Location 来确定跳转到的新url地址</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">root@sz3:~# curl -L -I <span class="s2">&#34;http://runreport.dnion.com/DCC/logDownLoad.do?user=user1&amp;password=password1&amp;domain=rtmpdist-d.quklive.com&amp;date=20171026&amp;hour=10&#34;</span>
HTTP/1.1 <span class="m">302</span> Moved Temporarily
Server: Apache-Coyote/1.1
Set-Cookie: <span class="nv">JSESSIONID</span><span class="o">=</span>0F11668F6EBF4DC16B43E322CCF16C85<span class="p">;</span> <span class="nv">Path</span><span class="o">=</span>/DCC
Location: http://runreport.dnion.com/logDownLoad.do?user<span class="o">=</span>qukan<span class="p">&amp;</span><span class="nv">password</span><span class="o">=</span>0cddcbf6d292fab5de0aas931bf19c<span class="p">&amp;</span><span class="nv">domain</span><span class="o">=</span>rtmpdist-d.quklive.com<span class="p">&amp;</span><span class="nv">date</span><span class="o">=</span>20171026<span class="p">&amp;</span><span class="nv">hour</span><span class="o">=</span><span class="m">10</span>
Content-Type: text/html<span class="p">;</span><span class="nv">charset</span><span class="o">=</span>GBK
Content-Length: <span class="m">0</span>
Date: Mon, <span class="m">06</span> Nov <span class="m">2017</span> 09:46:44 GMT

HTTP/1.1 <span class="m">302</span> Moved Temporarily
Server: Apache-Coyote/1.1
Location: ftp://ABA606843D412DAE34F28CDB23F7A31E:0687B16F2F5D0A2637FACDB23FAC982179411FA7466F10B2E7D0F4AA2D7F6AD42536F122549D0A6E40337E896@125.39.237.48:55621/rtmpdist-d.quklive.com_20171026_10_11.gz
Content-Type: text/html<span class="p">;</span><span class="nv">charset</span><span class="o">=</span>GBK
Content-Length: <span class="m">0</span>
Date: Mon, <span class="m">06</span> Nov <span class="m">2017</span> 09:46:44 GMT

Last-Modified: Thu, <span class="m">26</span> Oct <span class="m">2017</span> 02:30:13 GMT
Content-Length: <span class="m">1932</span>
Accept-ranges: bytes
</code></pre></td></tr></table>
</div>
</div><p>最后跳转到需要的ftp链接。</p>
<h1 id="http重定向抓包验证">HTTP重定向抓包验证</h1>
<p>使用wireshark抓包结果如下：</p>
<p>第一次跳转过程如下图</p>
<p><img src="https://flowsnow.oss-cn-shanghai.aliyuncs.com/history/image/blog/dnion_http302_first%E8%B7%B3%E8%BD%AC.jpg" alt=""></p>
<p>第二次跳转过程如下图</p>
<p><img src="https://flowsnow.oss-cn-shanghai.aliyuncs.com/history/image/blog/dnion_http302_final%E8%B7%B3%E8%BD%AC.jpg" alt=""></p>
<p>所以通过抓包可以清晰的看到302跳转的过程</p>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://www.cnblogs.com/sunada2005/p/3829772.html">csdn-curl命令的常见参数使用</a></li>
<li><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Redirections">mozilla-HTTP 的重定向</a></li>
</ol>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Suncle</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2017-11-08
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞赏支持</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="https://flowsnow.oss-cn-shanghai.aliyuncs.com/history/wechat-reward-image.png">
        <span>微信打赏</span>
      </label>
    <label class="qr-code-image" for="reward">
        <img class="image" src="https://flowsnow.oss-cn-shanghai.aliyuncs.com/history/alipay-reward-image.jpg">
        <span>支付宝打赏</span>
      </label>
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/Http/">Http</a>
          <a href="/tags/%E9%87%8D%E5%AE%9A%E5%90%91/">重定向</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/2017/11/10/ubuntu16-04%E5%AE%89%E5%85%A8%E5%B0%8F%E7%BB%93-01/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">ubuntu16.04安全小结-01</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/2017/10/31/%E6%80%9D%E8%80%83%E4%B8%80%E6%AC%A1%E6%95%B4%E4%BD%93%E8%B0%83%E6%95%B4Python%E9%A1%B9%E7%9B%AE%E8%A7%84%E8%8C%83%E6%80%A7%E7%9A%84%E8%BF%87%E7%A8%8B/">
            <span class="next-text nav-default">思考一次整体调整Python项目规范性的过程</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="suncle1993/suncle1993.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:im.suncle@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.facebook.com/sunclechen" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://github.com/suncle1993" class="iconfont icon-github" title="github"></a>
      <a href="https://weibo.com/3655576503" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.zhihu.com/people/flowsnow" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://space.bilibili.com/362765899" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://suncle.me/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2015 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Suncle</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.d7b7ada643c9c1a983026e177f141f7363b4640d619caf01d8831a6718cd44ea.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-72506112-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script id="baidu_analytics">
  var _hmt = _hmt || [];
  (function() {
    if (window.location.hostname === 'localhost') return;
    var hm = document.createElement("script"); hm.async = true;
    hm.src = "https://hm.baidu.com/hm.js?41fc030db57d5570dd22f78997dc4a7e";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>

<script id="baidu_push">
  (function(){
    if (window.location.hostname === 'localhost') return;
    var bp = document.createElement('script'); bp.async = true;
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
  })();
</script>




</body>
</html>
